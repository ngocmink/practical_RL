{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ngocmink/practical_RL/blob/main/week06_policy_based/reinforce_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nz0u1zHzdR1i"
      },
      "source": [
        "# REINFORCE in PyTorch\n",
        "\n",
        "Just like we did before for Q-learning, this time we'll design a PyTorch network to learn `CartPole-v0` via policy gradient (REINFORCE).\n",
        "\n",
        "Most of the code in this notebook is taken from approximate Q-learning, so you'll find it more or less familiar and even simpler."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bLVYFFnYdR1o",
        "outputId": "b249e321-a6c6-4895-8d94-85379b18a94c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.12/dist-packages (1.0.3)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.12/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.12/dist-packages (from moviepy) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.12/dist-packages (from moviepy) (2.32.4)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.12/dist-packages (from moviepy) (0.1.12)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.12/dist-packages (from moviepy) (2.0.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.12/dist-packages (from moviepy) (2.37.0)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from moviepy) (0.6.0)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.12/dist-packages (from imageio<3.0,>=2.5->moviepy) (11.3.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2025.10.5)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 47 not upgraded.\n",
            "Requirement already satisfied: imageio-ffmpeg in /usr/local/lib/python3.12/dist-packages (0.6.0)\n",
            "Starting virtual X frame buffer: Xvfb.\n"
          ]
        }
      ],
      "source": [
        "import sys, os\n",
        "if 'google.colab' in sys.modules and not os.path.exists('.setup_complete'):\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/setup_colab.sh -O- | bash\n",
        "    !pip install -q gymnasium\n",
        "    !pip install moviepy\n",
        "    !apt install ffmpeg\n",
        "    !pip install imageio-ffmpeg\n",
        "    !touch .setup_complete\n",
        "\n",
        "# This code creates a virtual display to draw game images on.\n",
        "# It will have no effect if your machine has a monitor.\n",
        "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\")) == 0:\n",
        "    !bash ../xvfb start\n",
        "    os.environ['DISPLAY'] = ':1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pizobAxGdR1r"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3DNz20N4dR1s",
        "outputId": "8ad16d9a-d81f-48c1-b610-b3e9db9b0c73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ffmpeg\n",
            "  Downloading ffmpeg-1.4.tar.gz (5.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: ffmpeg\n",
            "  Building wheel for ffmpeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpeg: filename=ffmpeg-1.4-py3-none-any.whl size=6083 sha256=c45a44d92f8a79f8462593b867facf8a3924713ee8ea900fb4d18fc1e0f4904b\n",
            "  Stored in directory: /root/.cache/pip/wheels/26/21/0c/c26e09dff860a9071683e279445262346e008a9a1d2142c4ad\n",
            "Successfully built ffmpeg\n",
            "Installing collected packages: ffmpeg\n",
            "Successfully installed ffmpeg-1.4\n"
          ]
        }
      ],
      "source": [
        "# also you need to install ffmpeg if not installed\n",
        "# for MacOS: ! brew install ffmpeg\n",
        "!pip install ffmpeg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KbKw-5qdR1t"
      },
      "source": [
        "A caveat: with some versions of `pyglet`, the following cell may crash with `NameError: name 'base' is not defined`. The corresponding bug report is [here](https://github.com/pyglet/pyglet/issues/134). If you see this error, try restarting the kernel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "pEOy6OF3dR1u",
        "outputId": "5cd6ea77-d718-4316-b2f6-39a7780564cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.int64(2)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAF7CAYAAAD4/3BBAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAKM1JREFUeJzt3X1wVFWe//FPdx6ah9AdAySdSIKojBAgOAsYenVcXDIEREfWWKUOK3GWkpJNrNE4DmbWUXG2jItT68Oswh+7K26VDI5ToiMjOBEkrGNAjGR5UDPAj5ngkE5QNt1JkJCkz+8Plju2ItAhpE8n71fVrUrfc7r7e0+Fzodzz73tMsYYAQAAWMQd7wIAAAC+ioACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKwT14Dy3HPP6ZJLLtGQIUNUWFio999/P57lAAAAS8QtoLz88suqqKjQI488og8//FBTp05VcXGxWlpa4lUSAACwhCteXxZYWFioGTNm6N/+7d8kSZFIRLm5ubrnnnv04IMPxqMkAABgieR4vOmJEydUV1enyspKZ5/b7VZRUZFqa2u/1r+zs1OdnZ3O40gkoqNHj2rkyJFyuVz9UjMAADg/xhi1tbUpJydHbveZT+LEJaB89tln6unpUVZWVtT+rKwsffLJJ1/rX1VVpeXLl/dXeQAA4AI6dOiQxowZc8Y+cQkosaqsrFRFRYXzOBQKKS8vT4cOHZLX641jZQAA4FyFw2Hl5uZqxIgRZ+0bl4AyatQoJSUlqbm5OWp/c3Oz/H7/1/p7PB55PJ6v7fd6vQQUAAASzLksz4jLVTypqamaNm2aNm3a5OyLRCLatGmTAoFAPEoCAAAWidspnoqKCpWWlmr69Om66qqr9PTTT6ujo0M/+MEP4lUSAACwRNwCyq233qojR47o4YcfVjAY1JVXXqmNGzd+beEsAAAYfOJ2H5TzEQ6H5fP5FAqFWIMCAECCiOXvN9/FAwAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgnT4PKI8++qhcLlfUNmHCBKf9+PHjKisr08iRI5WWlqaSkhI1Nzf3dRkAACCBXZAZlEmTJqmpqcnZ3n33Xaftvvvu0xtvvKFXXnlFNTU1Onz4sG6++eYLUQYAAEhQyRfkRZOT5ff7v7Y/FArpP/7jP7RmzRr97d/+rSTphRde0MSJE7Vt2zbNnDnzQpQDAAASzAWZQdm3b59ycnJ06aWXauHChWpsbJQk1dXVqaurS0VFRU7fCRMmKC8vT7W1td/4ep2dnQqHw1EbAAAYuPo8oBQWFmr16tXauHGjVq5cqYMHD+o73/mO2traFAwGlZqaqvT09KjnZGVlKRgMfuNrVlVVyefzOVtubm5flw0AACzS56d45s2b5/xcUFCgwsJCjR07Vr/61a80dOjQXr1mZWWlKioqnMfhcJiQAgDAAHbBLzNOT0/Xt771Le3fv19+v18nTpxQa2trVJ/m5ubTrlk5xePxyOv1Rm0AAGDguuABpb29XQcOHFB2dramTZumlJQUbdq0yWlvaGhQY2OjAoHAhS4FAAAkiD4/xfOjH/1IN954o8aOHavDhw/rkUceUVJSkm6//Xb5fD4tXrxYFRUVysjIkNfr1T333KNAIMAVPAAAwNHnAeXTTz/V7bffrs8//1yjR4/WNddco23btmn06NGSpKeeekput1slJSXq7OxUcXGxnn/++b4uAwAAJDCXMcbEu4hYhcNh+Xw+hUIh1qMAAJAgYvn7zXfxAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsE3NA2bp1q2688Ubl5OTI5XLptddei2o3xujhhx9Wdna2hg4dqqKiIu3bty+qz9GjR7Vw4UJ5vV6lp6dr8eLFam9vP68DAQAAA0fMAaWjo0NTp07Vc889d9r2FStW6Nlnn9WqVau0fft2DR8+XMXFxTp+/LjTZ+HChdq7d6+qq6u1fv16bd26VUuWLOn9UQAAgAHFZYwxvX6yy6V169ZpwYIFkk7OnuTk5Oj+++/Xj370I0lSKBRSVlaWVq9erdtuu00ff/yx8vPztWPHDk2fPl2StHHjRl1//fX69NNPlZOTc9b3DYfD8vl8CoVC8nq9vS0fAAD0o1j+fvfpGpSDBw8qGAyqqKjI2efz+VRYWKja2lpJUm1trdLT051wIklFRUVyu93avn37aV+3s7NT4XA4agMAAANXnwaUYDAoScrKyoran5WV5bQFg0FlZmZGtScnJysjI8Pp81VVVVXy+XzOlpub25dlAwAAyyTEVTyVlZUKhULOdujQoXiXBAAALqA+DSh+v1+S1NzcHLW/ubnZafP7/WppaYlq7+7u1tGjR50+X+XxeOT1eqM2AAAwcPVpQBk3bpz8fr82bdrk7AuHw9q+fbsCgYAkKRAIqLW1VXV1dU6fzZs3KxKJqLCwsC/LAQAACSo51ie0t7dr//79zuODBw+qvr5eGRkZysvL07333qt//ud/1vjx4zVu3Dj99Kc/VU5OjnOlz8SJEzV37lzdddddWrVqlbq6ulReXq7bbrvtnK7gAQAAA1/MAeWDDz7Qdddd5zyuqKiQJJWWlmr16tX68Y9/rI6ODi1ZskStra265pprtHHjRg0ZMsR5zksvvaTy8nLNnj1bbrdbJSUlevbZZ/vgcAAAwEBwXvdBiRfugwIAQOKJ231QAAAA+gIBBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdWIOKFu3btWNN96onJwcuVwuvfbaa1Htd955p1wuV9Q2d+7cqD5Hjx7VwoUL5fV6lZ6ersWLF6u9vf28DgQAAAwcMQeUjo4OTZ06Vc8999w39pk7d66ampqc7Ze//GVU+8KFC7V3715VV1dr/fr12rp1q5YsWRJ79QAAYEBKjvUJ8+bN07x5887Yx+PxyO/3n7bt448/1saNG7Vjxw5Nnz5dkvSLX/xC119/vX7+858rJycn1pIAAMAAc0HWoGzZskWZmZm64oortHTpUn3++edOW21trdLT051wIklFRUVyu93avn37aV+vs7NT4XA4agMAAANXnweUuXPn6r/+67+0adMm/cu//Itqamo0b9489fT0SJKCwaAyMzOjnpOcnKyMjAwFg8HTvmZVVZV8Pp+z5ebm9nXZAADAIjGf4jmb2267zfl5ypQpKigo0GWXXaYtW7Zo9uzZvXrNyspKVVRUOI/D4TAhBQCAAeyCX2Z86aWXatSoUdq/f78kye/3q6WlJapPd3e3jh49+o3rVjwej7xeb9QGAAAGrgseUD799FN9/vnnys7OliQFAgG1traqrq7O6bN582ZFIhEVFhZe6HIAAEACiPkUT3t7uzMbIkkHDx5UfX29MjIylJGRoeXLl6ukpER+v18HDhzQj3/8Y11++eUqLi6WJE2cOFFz587VXXfdpVWrVqmrq0vl5eW67bbbuIIHAABIklzGGBPLE7Zs2aLrrrvua/tLS0u1cuVKLViwQDt37lRra6tycnI0Z84c/exnP1NWVpbT9+jRoyovL9cbb7wht9utkpISPfvss0pLSzunGsLhsHw+n0KhEKd7AABIELH8/Y45oNiAgAIAQOKJ5e8338UDAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANaJ+csCAaCvdRz5k/78wW/O2MczYqTGXvP9fqoIQLwRUADEXffxdoUad5+xz9CMixWJ9MjtTuqnqgDEE6d4ACQGY6RIJN5VAOgnBBQACcHIyER64l0GgH5CQAGQGAwBBRhMCCgAEgYBBRg8CCgAEoIxRsYQUIDBgoACIDEYI8MiWWDQIKAASBCsQQEGEwIKgMTAIllgUCGgAEgIRiySBQYTAgqAxMAMCjCoEFAAJAgCCjCYEFAAJATDVTzAoEJAAZAguA8KMJgQUAAkBsMiWWAwIaAASBCsQQEGEwIKgLhzJ6cqyTPsjH0iPV3q6gj1U0UA4o2AAiDuUoana/iosWfs09N5TG3Bff1UEYB4I6AAiDuXyyW5+TgC8BcxfSJUVVVpxowZGjFihDIzM7VgwQI1NDRE9Tl+/LjKyso0cuRIpaWlqaSkRM3NzVF9GhsbNX/+fA0bNkyZmZl64IEH1N3dff5HAyBBueRyEVAA/EVMnwg1NTUqKyvTtm3bVF1dra6uLs2ZM0cdHR1On/vuu09vvPGGXnnlFdXU1Ojw4cO6+eabnfaenh7Nnz9fJ06c0HvvvacXX3xRq1ev1sMPP9x3RwUgobhcbrncSfEuA4BFXMYY09snHzlyRJmZmaqpqdG1116rUCik0aNHa82aNbrlllskSZ988okmTpyo2tpazZw5Uxs2bNANN9ygw4cPKysrS5K0atUqLVu2TEeOHFFqaupZ3zccDsvn8ykUCsnr9fa2fACWONHRqsb31up//9+HZ+w38lsBXXrdD/qpKgB9LZa/3+c1pxoKnVxRn5GRIUmqq6tTV1eXioqKnD4TJkxQXl6eamtrJUm1tbWaMmWKE04kqbi4WOFwWHv37j3t+3R2diocDkdtAAYOl8sll4sZFAB/0euAEolEdO+99+rqq6/W5MmTJUnBYFCpqalKT0+P6puVlaVgMOj0+XI4OdV+qu10qqqq5PP5nC03N7e3ZQOwkcslF4tkAXxJrz8RysrKtGfPHq1du7Yv6zmtyspKhUIhZzt06NAFf08A/cktsUgWwJck9+ZJ5eXlWr9+vbZu3aoxY8Y4+/1+v06cOKHW1taoWZTm5mb5/X6nz/vvvx/1eqeu8jnV56s8Ho88Hk9vSgWQAFzMoAD4ipg+EYwxKi8v17p167R582aNGzcuqn3atGlKSUnRpk2bnH0NDQ1qbGxUIBCQJAUCAe3evVstLS1On+rqanm9XuXn55/PsQBIVKxBAfAVMc2glJWVac2aNXr99dc1YsQIZ82Iz+fT0KFD5fP5tHjxYlVUVCgjI0Ner1f33HOPAoGAZs6cKUmaM2eO8vPzdccdd2jFihUKBoN66KGHVFZWxiwJMEgxgwLgq2IKKCtXrpQkzZo1K2r/Cy+8oDvvvFOS9NRTT8ntdqukpESdnZ0qLi7W888/7/RNSkrS+vXrtXTpUgUCAQ0fPlylpaV67LHHzu9IACQuF2tQAEQ7r/ugxAv3QQEGlkj3CX2643U176o+Yz/ugwIktn67DwoA9AkXt7oHEI1PBAAWYA0KgGh8IgCIO5fLzVU8AKIQUADEn8slneMMSgIumwPQCwQUAFZwuVxn70Q4AQYNAgqAuDuncCLJmIhkIhe4GgA2IKAASBzGnAwpAAY8AgqAhGFMRCZCQAEGAwIKgMTBKR5g0CCgAEgYxhiu4gEGCQIKgITBKR5g8CCgAEgcxnCKBxgkCCgAEoYxEa7iAQYJAgqAxBEhoACDBQEFQMIwJiKxBgUYFAgoABIHN2oDBg0CCoCEwRoUYPAgoABIGIareIBBg4ACIHFwHxRg0CCgAEgYJ7/NmDvJAoMBAQVA4mCRLDBoEFAAWMHjzVTy0BFn7HOi/X/V2fZZP1UEIJ4IKACskJqWoeQhaWfs0328TV3HQv1UEYB4IqAAsILL7ZbLxUcSgJP4NABgBZfLLblc8S4DgCUIKACswAwKgC/j0wCAHVxJzKAAcBBQAFjB5XLLJQIKgJMIKACs4HK7JTcfSQBO4tMAgBWYQQHwZQQUAHZwuyUWyQL4PzF9GlRVVWnGjBkaMWKEMjMztWDBAjU0NET1mTVrllwuV9R29913R/VpbGzU/PnzNWzYMGVmZuqBBx5Qd3f3+R8NgITlcrnlYpEsgP+THEvnmpoalZWVacaMGeru7tZPfvITzZkzRx999JGGDx/u9Lvrrrv02GOPOY+HDRvm/NzT06P58+fL7/frvffeU1NTkxYtWqSUlBQ9/vjjfXBIABKRy53EDAoAR0wBZePGjVGPV69erczMTNXV1enaa6919g8bNkx+v/+0r/G73/1OH330kd5++21lZWXpyiuv1M9+9jMtW7ZMjz76qFJTU3txGAASHTMoAL7svP67Egqd/E6MjIyMqP0vvfSSRo0apcmTJ6uyslLHjh1z2mprazVlyhRlZWU5+4qLixUOh7V3797Tvk9nZ6fC4XDUBmCAcXMnWQB/EdMMypdFIhHde++9uvrqqzV58mRn//e//32NHTtWOTk52rVrl5YtW6aGhga9+uqrkqRgMBgVTiQ5j4PB4Gnfq6qqSsuXL+9tqQASwMkZFE7xADip1wGlrKxMe/bs0bvvvhu1f8mSJc7PU6ZMUXZ2tmbPnq0DBw7osssu69V7VVZWqqKiwnkcDoeVm5vbu8IBWInv4gHwZb3670p5ebnWr1+vd955R2PGjDlj38LCQknS/v37JUl+v1/Nzc1RfU49/qZ1Kx6PR16vN2oDMMC4WYMC4C9iCijGGJWXl2vdunXavHmzxo0bd9bn1NfXS5Kys7MlSYFAQLt371ZLS4vTp7q6Wl6vV/n5+bGUA2AAOTmDcm4fScaYC1wNgHiL6RRPWVmZ1qxZo9dff10jRoxw1oz4fD4NHTpUBw4c0Jo1a3T99ddr5MiR2rVrl+677z5de+21KigokCTNmTNH+fn5uuOOO7RixQoFg0E99NBDKisrk8fj6fsjBJAQznX2xEQiF7gSADaIaQZl5cqVCoVCmjVrlrKzs53t5ZdfliSlpqbq7bff1pw5czRhwgTdf//9Kikp0RtvvOG8RlJSktavX6+kpCQFAgH9/d//vRYtWhR13xQA+CYm0iMxgwIMeDHNoJxtWjU3N1c1NTVnfZ2xY8fqzTffjOWtAUCSZExERoZv7QEGOK7pA5BYmEEBBgUCCoCEYiIRAgowCBBQACQUY3pkREABBjoCCoCEwgwKMDgQUAAkFK7iAQYHAgqAhHLqKh4AAxsBBUBCYQYFGBwIKAASCmtQgMGBgAIgoZgIV/EAgwEBBUBiMZziAQYDAgqAhMIpHmBwIKAASCgm0nPW7wUDkPgIKAASijERiTUowIBHQAGQULjMGBgcCCgArOHLK5A7ZcgZ+7Q1/UFdx0L9VBGAeCGgALBGytA0udxJZ+wT6eo8OYsCYEAjoACwhsudJFe8iwBgBQIKAGu4XEmSi4gCgIACwCKupCSJORQAkpLjXQCAgcEYo56e81sbEjnHi3N6enrU3d3d6/dJSkqSi5kawGoEFAB9Yt++fZo0adJ5vcaEvJF68u4ijfQOO2O/Wdddpz0HW3r1Hh6PR+FwmIACWI6AAqBPGGPOa1ZDkjpPdJ3TLU56erp7/V5JSWe+SgiAHQgoAKzR3RM5GXRMspo7L9EXkRFyySgt6X+Vmfon1s8CgwgBBYA1unsiihiXPgzPUVv3SJ0wHrlklOr+Qke6cjU57d14lwignxBQAFgjYtzaFvqeUtMu1qmreYykzkiaPj0+QW5FNHF4bVxrBNA/uMwYgDWuKfqJUoaP0+kuNTZy60/HJ6nxeH7/Fwag3xFQAFjD5dJZrq5x8T3GwCBBQAEAANYhoAAAAOsQUABY443Xfqb20CHptCdyjC72NCh3yCf9XRaAOIgpoKxcuVIFBQXyer3yer0KBALasGGD0378+HGVlZVp5MiRSktLU0lJiZqbm6Neo7GxUfPnz9ewYcOUmZmpBx544Lxv7gRgYDj2RZsC3l/Jm/SZkl2dkiJyKaIU1xfKTj2gKWk1SnKd3+30ASSGmC4zHjNmjJ544gmNHz9exhi9+OKLuummm7Rz505NmjRJ9913n37729/qlVdekc/nU3l5uW6++Wb9/ve/l3Ty+zPmz58vv9+v9957T01NTVq0aJFSUlL0+OOPX5ADBJA4jJHe/uCA0tJ+rj8fH6+OnovkUkTe5M/UPmSf/vh//Y6Gv4hnmQD6gcuYc7mx9DfLyMjQk08+qVtuuUWjR4/WmjVrdMstt0iSPvnkE02cOFG1tbWaOXOmNmzYoBtuuEGHDx9WVlaWJGnVqlVatmyZjhw5otTU1HN6z3A4LJ/PpzvvvPOcnwPgwgqFQnr55ZfjXcZZud1uLV68mO/iAeLgxIkTWr16tUKhkLxe7xn79vpGbT09PXrllVfU0dGhQCCguro6dXV1qaioyOkzYcIE5eXlOQGltrZWU6ZMccKJJBUXF2vp0qXau3evvv3tb5/2vTo7O9XZ2ek8DofDkqQ77rhDaWlpvT0EAH2osbExIQJKUlISAQWIk/b2dq1evfqc+sYcUHbv3q1AIKDjx48rLS1N69atU35+vurr65Wamqr09PSo/llZWQoGg5KkYDAYFU5OtZ9q+yZVVVVavnz51/ZPnz79rAkMQP/w+XzxLuGcuN1uzZgxQ2431wgA/e3UBMO5iPlf6BVXXKH6+npt375dS5cuVWlpqT766KNYXyYmlZWVCoVCznbo0KEL+n4AACC+Yp5BSU1N1eWXXy5JmjZtmnbs2KFnnnlGt956q06cOKHW1taoWZTm5mb5/X5Jkt/v1/vvvx/1eqeu8jnV53Q8Ho88Hk+spQIAgAR13nOckUhEnZ2dmjZtmlJSUrRp0yanraGhQY2NjQoEApKkQCCg3bt3q6WlxelTXV0tr9er/Hy+XwMAAJwU0wxKZWWl5s2bp7y8PLW1tWnNmjXasmWL3nrrLfl8Pi1evFgVFRXKyMiQ1+vVPffco0AgoJkzZ0qS5syZo/z8fN1xxx1asWKFgsGgHnroIZWVlTFDAgAAHDEFlJaWFi1atEhNTU3y+XwqKCjQW2+9pe9+97uSpKeeekput1slJSXq7OxUcXGxnn/+eef5SUlJWr9+vZYuXapAIKDhw4ertLRUjz32WN8eFQAASGjnfR+UeDh1H5RzuY4aQP9oaGjQhAkT4l3GWXk8Hh07doyreIA4iOXvN/9CAQCAdQgoAADAOgQUAABgHQIKAACwTq+/iwcAviwtLU0LFiyIdxlnlZKSEu8SAJwDAgqAPnHxxRdr3bp18S4DwADBKR4AAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6MQWUlStXqqCgQF6vV16vV4FAQBs2bHDaZ82aJZfLFbXdfffdUa/R2Nio+fPna9iwYcrMzNQDDzyg7u7uvjkaAAAwICTH0nnMmDF64oknNH78eBlj9OKLL+qmm27Szp07NWnSJEnSXXfdpccee8x5zrBhw5yfe3p6NH/+fPn9fr333ntqamrSokWLlJKSoscff7yPDgkAACQ6lzHGnM8LZGRk6Mknn9TixYs1a9YsXXnllXr66adP23fDhg264YYbdPjwYWVlZUmSVq1apWXLlunIkSNKTU09p/cMh8Py+XwKhULyer3nUz4AAOgnsfz97vUalJ6eHq1du1YdHR0KBALO/pdeekmjRo3S5MmTVVlZqWPHjjlttbW1mjJlihNOJKm4uFjhcFh79+79xvfq7OxUOByO2gAAwMAV0ykeSdq9e7cCgYCOHz+utLQ0rVu3Tvn5+ZKk73//+xo7dqxycnK0a9cuLVu2TA0NDXr11VclScFgMCqcSHIeB4PBb3zPqqoqLV++PNZSAQBAgoo5oFxxxRWqr69XKBTSr3/9a5WWlqqmpkb5+flasmSJ02/KlCnKzs7W7NmzdeDAAV122WW9LrKyslIVFRXO43A4rNzc3F6/HgAAsFvMp3hSU1N1+eWXa9q0aaqqqtLUqVP1zDPPnLZvYWGhJGn//v2SJL/fr+bm5qg+px77/f5vfE+Px+NcOXRqAwAAA9d53wclEomos7PztG319fWSpOzsbElSIBDQ7t271dLS4vSprq6W1+t1ThMBAADEdIqnsrJS8+bNU15entra2rRmzRpt2bJFb731lg4cOKA1a9bo+uuv18iRI7Vr1y7dd999uvbaa1VQUCBJmjNnjvLz83XHHXdoxYoVCgaDeuihh1RWViaPx3NBDhAAACSemAJKS0uLFi1apKamJvl8PhUUFOitt97Sd7/7XR06dEhvv/22nn76aXV0dCg3N1clJSV66KGHnOcnJSVp/fr1Wrp0qQKBgIYPH67S0tKo+6YAAACc931Q4oH7oAAAkHj65T4oAAAAFwoBBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwTnK8C+gNY4wkKRwOx7kSAABwrk793T71d/xMEjKgtLW1SZJyc3PjXAkAAIhVW1ubfD7fGfu4zLnEGMtEIhE1NDQoPz9fhw4dktfrjXdJCSscDis3N5dx7AOMZd9hLPsG49h3GMu+YYxRW1ubcnJy5HafeZVJQs6guN1uXXzxxZIkr9fLL0sfYBz7DmPZdxjLvsE49h3G8vydbebkFBbJAgAA6xBQAACAdRI2oHg8Hj3yyCPyeDzxLiWhMY59h7HsO4xl32Ac+w5j2f8ScpEsAAAY2BJ2BgUAAAxcBBQAAGAdAgoAALAOAQUAAFgnIQPKc889p0suuURDhgxRYWGh3n///XiXZJ2tW7fqxhtvVE5Ojlwul1577bWodmOMHn74YWVnZ2vo0KEqKirSvn37ovocPXpUCxculNfrVXp6uhYvXqz29vZ+PIr4q6qq0owZMzRixAhlZmZqwYIFamhoiOpz/PhxlZWVaeTIkUpLS1NJSYmam5uj+jQ2Nmr+/PkaNmyYMjMz9cADD6i7u7s/DyWuVq5cqYKCAucmV4FAQBs2bHDaGcPee+KJJ+RyuXTvvfc6+xjPc/Poo4/K5XJFbRMmTHDaGcc4Mwlm7dq1JjU11fznf/6n2bt3r7nrrrtMenq6aW5ujndpVnnzzTfNP/3TP5lXX33VSDLr1q2Lan/iiSeMz+czr732mvmf//kf873vfc+MGzfOfPHFF06fuXPnmqlTp5pt27aZ//7v/zaXX365uf322/v5SOKruLjYvPDCC2bPnj2mvr7eXH/99SYvL8+0t7c7fe6++26Tm5trNm3aZD744AMzc+ZM89d//ddOe3d3t5k8ebIpKioyO3fuNG+++aYZNWqUqaysjMchxcVvfvMb89vf/tb84Q9/MA0NDeYnP/mJSUlJMXv27DHGMIa99f7775tLLrnEFBQUmB/+8IfOfsbz3DzyyCNm0qRJpqmpydmOHDnitDOO8ZVwAeWqq64yZWVlzuOenh6Tk5Njqqqq4liV3b4aUCKRiPH7/ebJJ5909rW2thqPx2N++ctfGmOM+eijj4wks2PHDqfPhg0bjMvlMn/+85/7rXbbtLS0GEmmpqbGGHNy3FJSUswrr7zi9Pn444+NJFNbW2uMORkW3W63CQaDTp+VK1car9drOjs7+/cALHLRRReZf//3f2cMe6mtrc2MHz/eVFdXm7/5m79xAgrjee4eeeQRM3Xq1NO2MY7xl1CneE6cOKG6ujoVFRU5+9xut4qKilRbWxvHyhLLwYMHFQwGo8bR5/OpsLDQGcfa2lqlp6dr+vTpTp+ioiK53W5t376932u2RSgUkiRlZGRIkurq6tTV1RU1lhMmTFBeXl7UWE6ZMkVZWVlOn+LiYoXDYe3du7cfq7dDT0+P1q5dq46ODgUCAcawl8rKyjR//vyocZP4nYzVvn37lJOTo0svvVQLFy5UY2OjJMbRBgn1ZYGfffaZenp6on4ZJCkrK0uffPJJnKpKPMFgUJJOO46n2oLBoDIzM6Pak5OTlZGR4fQZbCKRiO69915dffXVmjx5sqST45Samqr09PSovl8dy9ON9am2wWL37t0KBAI6fvy40tLStG7dOuXn56u+vp4xjNHatWv14YcfaseOHV9r43fy3BUWFmr16tW64oor1NTUpOXLl+s73/mO9uzZwzhaIKECChBPZWVl2rNnj9599914l5KQrrjiCtXX1ysUCunXv/61SktLVVNTE++yEs6hQ4f0wx/+UNXV1RoyZEi8y0lo8+bNc34uKChQYWGhxo4dq1/96lcaOnRoHCuDlGBX8YwaNUpJSUlfW0Xd3Nwsv98fp6oSz6mxOtM4+v1+tbS0RLV3d3fr6NGjg3Ksy8vLtX79er3zzjsaM2aMs9/v9+vEiRNqbW2N6v/VsTzdWJ9qGyxSU1N1+eWXa9q0aaqqqtLUqVP1zDPPMIYxqqurU0tLi/7qr/5KycnJSk5OVk1NjZ599lklJycrKyuL8eyl9PR0fetb39L+/fv5vbRAQgWU1NRUTZs2TZs2bXL2RSIRbdq0SYFAII6VJZZx48bJ7/dHjWM4HNb27dudcQwEAmptbVVdXZ3TZ/PmzYpEIiosLOz3muPFGKPy8nKtW7dOmzdv1rhx46Lap02bppSUlKixbGhoUGNjY9RY7t69OyrwVVdXy+v1Kj8/v38OxEKRSESdnZ2MYYxmz56t3bt3q76+3tmmT5+uhQsXOj8znr3T3t6uAwcOKDs7m99LG8R7lW6s1q5dazwej1m9erX56KOPzJIlS0x6enrUKmqcXOG/c+dOs3PnTiPJ/Ou//qvZuXOn+dOf/mSMOXmZcXp6unn99dfNrl27zE033XTay4y//e1vm+3bt5t3333XjB8/ftBdZrx06VLj8/nMli1boi5FPHbsmNPn7rvvNnl5eWbz5s3mgw8+MIFAwAQCAaf91KWIc+bMMfX19Wbjxo1m9OjRg+pSxAcffNDU1NSYgwcPml27dpkHH3zQuFwu87vf/c4Ywxiery9fxWMM43mu7r//frNlyxZz8OBB8/vf/94UFRWZUaNGmZaWFmMM4xhvCRdQjDHmF7/4hcnLyzOpqanmqquuMtu2bYt3SdZ55513jKSvbaWlpcaYk5ca//SnPzVZWVnG4/GY2bNnm4aGhqjX+Pzzz83tt99u0tLSjNfrNT/4wQ9MW1tbHI4mfk43hpLMCy+84PT54osvzD/+4z+aiy66yAwbNsz83d/9nWlqaop6nT/+8Y9m3rx5ZujQoWbUqFHm/vvvN11dXf18NPHzD//wD2bs2LEmNTXVjB492syePdsJJ8YwhufrqwGF8Tw3t956q8nOzjapqanm4osvNrfeeqvZv3+/0844xpfLGGPiM3cDAABwegm1BgUAAAwOBBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWOf/A5rJBFz/CrctAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\n",
        "\n",
        "# gym compatibility: unwrap TimeLimit\n",
        "if hasattr(env, '_max_episode_steps'):\n",
        "    env = env.env\n",
        "\n",
        "env.reset()\n",
        "n_actions = env.action_space.n\n",
        "state_dim = env.observation_space.shape\n",
        "\n",
        "plt.imshow(env.render())\n",
        "n_actions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpOAEaItdR1u"
      },
      "source": [
        "# Building the network for REINFORCE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0N6GT5rQdR1v"
      },
      "source": [
        "For REINFORCE algorithm, we'll need a model that predicts action probabilities given states.\n",
        "\n",
        "For numerical stability, please __do not include the softmax layer into your network architecture__.\n",
        "We'll use softmax or log-softmax where appropriate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "REFJE09edR1x"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "s0it8k2rdR1y"
      },
      "outputs": [],
      "source": [
        "# Build a simple neural network that predicts policy logits.\n",
        "# Keep it simple: CartPole isn't worth deep architectures.\n",
        "model = nn.Sequential(\n",
        "  nn.Linear(state_dim[0], 10),\n",
        "  nn.ReLU(),\n",
        "  nn.Linear(10, n_actions)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSTh3VV9dR1z"
      },
      "source": [
        "#### Predict function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWgS1Z9rdR1z"
      },
      "source": [
        "Note: output value of this function is not a torch tensor, it's a numpy array.\n",
        "So, here gradient calculation is not needed.\n",
        "<br>\n",
        "Use [no_grad](https://pytorch.org/docs/stable/autograd.html#torch.autograd.no_grad)\n",
        "to suppress gradient calculation.\n",
        "<br>\n",
        "Also, `.detach()` (or legacy `.data` property) can be used instead, but there is a difference:\n",
        "<br>\n",
        "With `.detach()` computational graph is built but then disconnected from a particular tensor,\n",
        "so `.detach()` should be used if that graph is needed for backprop via some other (not detached) tensor;\n",
        "<br>\n",
        "In contrast, no graph is built by any operation in `no_grad()` context, thus it's preferable here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "a3CchVvkdR10"
      },
      "outputs": [],
      "source": [
        "def predict_probs(states):\n",
        "    \"\"\"\n",
        "    Predict action probabilities given states.\n",
        "    :param states: numpy array of shape [batch, state_shape]\n",
        "    :returns: numpy array of shape [batch, n_actions]\n",
        "    \"\"\"\n",
        "    # convert states, compute logits, use softmax to get probability\n",
        "    with torch.no_grad():\n",
        "      states = torch.tensor(states, dtype=torch.float32)\n",
        "      action = model(states)\n",
        "      sum = 0\n",
        "      sum = torch.sum(torch.exp(action), axis=1)\n",
        "      action = torch.exp(action) / sum.reshape(sum.shape[0], 1)\n",
        "      return action.detach().cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "cqr0xaGxdR10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "432550b3-31fc-44a4-920c-1f68f8696dff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 1. 1. 1. 1.]\n"
          ]
        }
      ],
      "source": [
        "test_states = np.array([env.reset()[0] for _ in range(5)])\n",
        "test_probas = predict_probs(test_states)\n",
        "assert isinstance(test_probas, np.ndarray), \\\n",
        "    \"you must return np array and not %s\" % type(test_probas)\n",
        "assert tuple(test_probas.shape) == (test_states.shape[0], env.action_space.n), \\\n",
        "    \"wrong output shape: %s\" % np.shape(test_probas)\n",
        "print(np.sum(test_probas, axis=1))\n",
        "assert np.allclose(np.sum(test_probas, axis=1), 1), \"probabilities do not sum to 1\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e04fHbEpdR11"
      },
      "source": [
        "### Play the game\n",
        "\n",
        "We can now use our newly built agent to play the game."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "kupI2RgDdR12"
      },
      "outputs": [],
      "source": [
        "def generate_session(env, t_max=1000):\n",
        "    \"\"\"\n",
        "    Play a full session with REINFORCE agent.\n",
        "    Returns sequences of states, actions, and rewards.\n",
        "    \"\"\"\n",
        "    # arrays to record session\n",
        "    states, actions, rewards = [], [], []\n",
        "\n",
        "    s = env.reset()[0]\n",
        "\n",
        "    for t in range(t_max):\n",
        "        # action probabilities array aka pi(a|s)\n",
        "        action_probs = predict_probs(np.array([s]))[0]\n",
        "\n",
        "        # Sample action with given probabilities.\n",
        "        a = np.random.choice(len(action_probs), p=action_probs)\n",
        "\n",
        "        new_s, r, terminated, truncated, info = env.step(a)\n",
        "\n",
        "        # record session history to train later\n",
        "        states.append(s)\n",
        "        actions.append(a)\n",
        "        rewards.append(r)\n",
        "\n",
        "        s = new_s\n",
        "        if terminated or truncated:\n",
        "            break\n",
        "\n",
        "    return states, actions, rewards"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "myeAR0TndR12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26d2bfd2-d1a6-4418-a02c-bf47a009ef15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "states: [[-0.04390145  0.03890746 -0.00464601  0.00784147]\n",
            " [-0.0431233  -0.15614755 -0.00448918  0.29905492]\n",
            " [-0.04624625 -0.35120523  0.00149192  0.5903187 ]\n",
            " [-0.05327036 -0.15610419  0.01329829  0.29810607]\n",
            " [-0.05639244 -0.35141316  0.01926041  0.5949532 ]\n",
            " [-0.06342071 -0.156566    0.03115948  0.30839887]\n",
            " [-0.06655202  0.03809843  0.03732745  0.02570337]\n",
            " [-0.06579006  0.23266575  0.03784152 -0.25497258]\n",
            " [-0.06113674  0.42722753  0.03274207 -0.5354836 ]\n",
            " [-0.05259219  0.62187415  0.0220324  -0.81767255]\n",
            " [-0.04015471  0.8166877   0.00567895 -1.1033449 ]\n",
            " [-0.02382095  0.6214915  -0.01638795 -0.80888575]\n",
            " [-0.01139112  0.81683415 -0.03256567 -1.1066782 ]\n",
            " [ 0.00494556  0.6221551  -0.05469923 -0.8243871 ]\n",
            " [ 0.01738866  0.4278223  -0.07118697 -0.5493974 ]\n",
            " [ 0.02594511  0.6238682  -0.08217492 -0.8636328 ]\n",
            " [ 0.03842247  0.82000697 -0.09944758 -1.1809803 ]\n",
            " [ 0.05482261  0.6263064  -0.12306719 -0.9210546 ]\n",
            " [ 0.06734874  0.43304318 -0.14148828 -0.6694428 ]\n",
            " [ 0.0760096   0.24014243 -0.15487713 -0.42444196]\n",
            " [ 0.08081245  0.4370802  -0.16336598 -0.76166475]\n",
            " [ 0.08955406  0.63403034 -0.17859927 -1.1009728 ]\n",
            " [ 0.10223466  0.8309946  -0.20061873 -1.4439491 ]]\n",
            "actions: [0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1]\n",
            "rewards: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
          ]
        }
      ],
      "source": [
        "# test it\n",
        "states, actions, rewards = generate_session(env)\n",
        "print(\"states:\", np.stack(states))\n",
        "print(\"actions:\", actions)\n",
        "print(\"rewards:\", rewards)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqQveZJ2dR13"
      },
      "source": [
        "### Computing cumulative rewards\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "G_t &= r_t + \\gamma r_{t + 1} + \\gamma^2 r_{t + 2} + \\ldots \\\\\n",
        "&= \\sum_{i = t}^T \\gamma^{i - t} r_i \\\\\n",
        "&= r_t + \\gamma * G_{t + 1}\n",
        "\\end{align*}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OwzjYyUWdR13"
      },
      "outputs": [],
      "source": [
        "def get_cumulative_rewards(rewards,  # rewards at each step\n",
        "                           gamma=0.99  # discount for reward\n",
        "                           ):\n",
        "    \"\"\"\n",
        "    Take a list of immediate rewards r(s,a) for the whole session\n",
        "    and compute cumulative returns (a.k.a. G(s,a) in Sutton '16).\n",
        "\n",
        "    G_t = r_t + gamma*r_{t+1} + gamma^2*r_{t+2} + ...\n",
        "\n",
        "    A simple way to compute cumulative rewards is to iterate from the last\n",
        "    to the first timestep and compute G_t = r_t + gamma*G_{t+1} recurrently\n",
        "\n",
        "    You must return an array/list of cumulative rewards with as many elements as in the initial rewards.\n",
        "    \"\"\"\n",
        "    <YOUR CODE>\n",
        "    return <YOUR CODE: array of cumulative rewards>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDyR9dwDdR14"
      },
      "outputs": [],
      "source": [
        "get_cumulative_rewards(rewards)\n",
        "assert len(get_cumulative_rewards(list(range(100)))) == 100\n",
        "assert np.allclose(\n",
        "    get_cumulative_rewards([0, 0, 1, 0, 0, 1, 0], gamma=0.9),\n",
        "    [1.40049, 1.5561, 1.729, 0.81, 0.9, 1.0, 0.0])\n",
        "assert np.allclose(\n",
        "    get_cumulative_rewards([0, 0, 1, -2, 3, -4, 0], gamma=0.5),\n",
        "    [0.0625, 0.125, 0.25, -1.5, 1.0, -4.0, 0.0])\n",
        "assert np.allclose(\n",
        "    get_cumulative_rewards([0, 0, 1, 2, 3, 4, 0], gamma=0),\n",
        "    [0, 0, 1, 2, 3, 4, 0])\n",
        "print(\"looks good!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LI3-IMj8dR14"
      },
      "source": [
        "#### Loss function and updates\n",
        "\n",
        "We now need to define objective and update over policy gradient.\n",
        "\n",
        "Our objective function is\n",
        "\n",
        "$$ J \\approx  { 1 \\over N } \\sum_{s_i,a_i} G(s_i,a_i) $$\n",
        "\n",
        "REINFORCE defines a way to compute the gradient of the expected reward with respect to policy parameters. The formula is as follows:\n",
        "\n",
        "$$ \\nabla_\\theta \\hat J(\\theta) \\approx { 1 \\over N } \\sum_{s_i, a_i} \\nabla_\\theta \\log \\pi_\\theta (a_i \\mid s_i) \\cdot G_t(s_i, a_i) $$\n",
        "\n",
        "We can abuse PyTorch's capabilities for automatic differentiation by defining our objective function as follows:\n",
        "\n",
        "$$ \\hat J(\\theta) \\approx { 1 \\over N } \\sum_{s_i, a_i} \\log \\pi_\\theta (a_i \\mid s_i) \\cdot G_t(s_i, a_i) $$\n",
        "\n",
        "When you compute the gradient of that function with respect to network weights $\\theta$, it will become exactly the policy gradient."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "STXAIuLkdR14"
      },
      "outputs": [],
      "source": [
        "# Your code: define optimizers\n",
        "optimizer = torch.optim.Adam(model.parameters(), 1e-3)\n",
        "\n",
        "\n",
        "def train_on_session(states, actions, rewards, gamma=0.99, entropy_coef=1e-2):\n",
        "    \"\"\"\n",
        "    Takes a sequence of states, actions and rewards produced by generate_session.\n",
        "    Updates agent's weights by following the policy gradient above.\n",
        "    Please use Adam optimizer with default parameters.\n",
        "    \"\"\"\n",
        "\n",
        "    # cast everything into torch tensors\n",
        "    states = torch.tensor(states, dtype=torch.float32)\n",
        "    actions = torch.tensor(actions, dtype=torch.int64)\n",
        "    cumulative_returns = np.array(get_cumulative_rewards(rewards, gamma))\n",
        "    cumulative_returns = torch.tensor(cumulative_returns, dtype=torch.float32)\n",
        "\n",
        "    # predict logits, probas and log-probas using an agent.\n",
        "    logits = model(states)\n",
        "    probs = nn.functional.softmax(logits, -1)\n",
        "    log_probs = nn.functional.log_softmax(logits, -1)\n",
        "\n",
        "    assert all(isinstance(v, torch.Tensor) for v in [logits, probs, log_probs]), \\\n",
        "        \"please use compute using torch tensors and don't use predict_probs function\"\n",
        "\n",
        "    # select log-probabilities for chosen actions, log pi(a_i|s_i)\n",
        "    log_probs_for_actions = torch.sum(\n",
        "        log_probs * F.one_hot(actions, env.action_space.n), dim=1)\n",
        "\n",
        "    # Compute loss here. Don't forgen entropy regularization with `entropy_coef`\n",
        "    entropy = <YOUR CODE>\n",
        "    loss = <YOUR CODE>\n",
        "\n",
        "    # Gradient descent step\n",
        "    <YOUR CODE>\n",
        "\n",
        "    # technical: return session rewards to print them later\n",
        "    return np.sum(rewards)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgFipOfIdR15"
      },
      "source": [
        "### The actual training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LUpH3cALdR15"
      },
      "outputs": [],
      "source": [
        "for i in range(100):\n",
        "    rewards = [train_on_session(*generate_session(env)) for _ in range(100)]  # generate new sessions\n",
        "\n",
        "    print(\"mean reward: %.3f\" % (np.mean(rewards)))\n",
        "\n",
        "    if np.mean(rewards) > 500:\n",
        "        print(\"You Win!\")  # but you can train even further\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9iuen04dR16"
      },
      "source": [
        "### Results & video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7eoppJ3AdR16"
      },
      "outputs": [],
      "source": [
        "# Record sessions\n",
        "\n",
        "from gymnasium.wrappers import RecordVideo\n",
        "\n",
        "with gym.make(\"CartPole-v1\", render_mode=\"rgb_array\") as env, RecordVideo(\n",
        "    env=env, video_folder=\"./videos\"\n",
        ") as env_monitor:\n",
        "    sessions = [generate_session(env_monitor) for _ in range(10)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VSHv_7wpdR16"
      },
      "outputs": [],
      "source": [
        "# Show video. This may not work in some setups. If it doesn't\n",
        "# work for you, you can download the videos and view them locally.\n",
        "\n",
        "from pathlib import Path\n",
        "from base64 import b64encode\n",
        "from IPython.display import HTML\n",
        "\n",
        "video_paths = sorted([s for s in Path('videos').iterdir() if s.suffix == '.mp4'])\n",
        "video_path = video_paths[-1]  # You can also try other indices\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "    # https://stackoverflow.com/a/57378660/1214547\n",
        "    with video_path.open('rb') as fp:\n",
        "        mp4 = fp.read()\n",
        "    data_url = 'data:video/mp4;base64,' + b64encode(mp4).decode()\n",
        "else:\n",
        "    data_url = str(video_path)\n",
        "\n",
        "HTML(\"\"\"\n",
        "<video width=\"640\" height=\"480\" controls>\n",
        "  <source src=\"{}\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\".format(data_url))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}